Natural Language Queries in Egocentric Videos

Egocentric Vision is a visual perception that captures human interactions that is centered around oneself or oneâ€™s own perspective. The Natural Language Queries (NLQ) for  egocentric vision are questions or requests phrased in everyday human language to interact with and retrieve information from first-person perspective videos. It plays a main role in various applications, including assistive robotics, autonomous driving, industrial applications and augmented reality. This article presents the results and analysis of using pre-extracted features such as omnivore and EgoVLP in two NLQ models: VSLBase and VSLNet on the Ego4D Natural Language Queries benchmark. Its purpose is to gain insight into the importance and use of the Natural Language Queries as well as compare our results with the official baseline results provided in the Ego4D paper. 
